{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging model\n",
    "Given the success of RF in predicting ETH in the previous model, I will be seeing if Bagging will be able to replicate the same level of success. In this, we will explore the bagging using decision trees as the estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the libraries and data\n",
    "To obtain the data, please go to notebooks/data_preprocessing, and then run data_import.ipynb and then run data_preprocessing.ipynb. This will give you data/processed_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Ticker',\n",
      "       'ln_hourly_return', 'ln_3_hourly_return', 'ln_hourly_rv',\n",
      "       'ln_3_hourly_rv', 'ln_daily_rv', 'ln_weekly_rv', 'ln_monthly_rv',\n",
      "       'ln_daily_rv_lag1', 'ln_daily_rv_lag2', 'ln_weekly_rv_lag1',\n",
      "       'ln_weekly_rv_lag2', 'ln_monthly_rv_lag1', 'ln_monthly_rv_lag2',\n",
      "       'ln_hourly_rv_lag1', 'ln_3_hourly_rv_lag1', 'ln_hourly_rv_lag2',\n",
      "       'ln_3_hourly_rv_lag2', 'ln_hourly_return_lag1',\n",
      "       'ln_3_hourly_return_lag1', 'ln_hourly_return_lag2',\n",
      "       'ln_3_hourly_return_lag2', 'Risk'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "data = pd.read_csv('../../data/processed_data.csv')\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "\n",
    "# Remove NaN values\n",
    "data = data.dropna()\n",
    "\n",
    "# Print columns\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split\n",
    "Now we will use a different train-test split from the group project\n",
    "Group project: 80/20 split\n",
    "Individual: Use 1 year of training data, then use rolling window "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-03 00:00:00+00:00 2024-05-03 00:00:00+00:00\n",
      "2024-05-03 01:00:00+00:00 2025-03-10 23:00:00+00:00\n"
     ]
    }
   ],
   "source": [
    "# Train-test split\n",
    "# Train data: 0.8 of the data\n",
    "# Test data: 0.2 of the data\n",
    "# Sort the data by date\n",
    "data = data.sort_values('Date')\n",
    "\n",
    "# Determine when the first year ends, and use it as train data\n",
    "# The rest of the data is used as test data\n",
    "min_date = data['Date'].min()\n",
    "max_date = data['Date'].max()\n",
    "\n",
    "# Calculate the total time span of the data\n",
    "total_time_span = max_date - min_date\n",
    "\n",
    "# Define the first year of data\n",
    "first_year_end = min_date + pd.DateOffset(years=1)\n",
    "\n",
    "# Filter data for the first year\n",
    "first_year_data = data[data['Date'] <= first_year_end]\n",
    "\n",
    "# Calculate the percentage of data in the first year\n",
    "percentage_first_year = (len(first_year_data) / len(data))\n",
    "\n",
    "train_split = percentage_first_year\n",
    "train_data = data[:int(train_split * len(data))]\n",
    "test_data = data[int(train_split * len(data)):]\n",
    "\n",
    "# Print train and test data date\n",
    "print(train_data['Date'].min(), train_data['Date'].max())\n",
    "print(test_data['Date'].min(), test_data['Date'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further split the data based on the risk level\n",
    "There are low, medium, and high risk models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split train and test data by risk groups\n",
    "train_data_split = {\n",
    "    'low': train_data[train_data['Risk'] == 'Low Risk'],\n",
    "    'medium': train_data[train_data['Risk'] == 'Medium Risk'],\n",
    "    'high': train_data[train_data['Risk'] == 'High Risk']\n",
    "}\n",
    "\n",
    "test_data_split = {\n",
    "    'low': test_data[test_data['Risk'] == 'Low Risk'],\n",
    "    'medium': test_data[test_data['Risk'] == 'Medium Risk'],\n",
    "    'high': test_data[test_data['Risk'] == 'High Risk']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model based on their classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This wil give us 3 models to work with: model_low, model_medium, and model_high. We will use these subsequent models on the test data to evaluate the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\young\\AppData\\Local\\Temp\\ipykernel_4348\\913764766.py:66: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  model_summary = pd.concat([\n"
     ]
    }
   ],
   "source": [
    "def train_models_by_frequency_and_risk(train_data, frequencies):\n",
    "    models = {}\n",
    "    model_summary = pd.DataFrame(columns=['Frequency', 'Risk Group', 'MSE (Train)', 'Top Features (Importance)'])  # Updated column name\n",
    "    \n",
    "    feature_map = {\n",
    "        'hourly': [\n",
    "            'ln_hourly_rv_lag1', 'ln_hourly_rv_lag2',\n",
    "            'ln_3_hourly_rv_lag1', 'ln_3_hourly_rv_lag2',\n",
    "            'ln_daily_rv_lag1', 'ln_daily_rv_lag2',\n",
    "            'ln_hourly_return_lag1', 'ln_hourly_return_lag2',\n",
    "            'ln_3_hourly_return_lag1', 'ln_3_hourly_return_lag2'\n",
    "        ],\n",
    "        '3hourly': [\n",
    "            'ln_3_hourly_rv_lag1', 'ln_3_hourly_rv_lag2',\n",
    "            'ln_daily_rv_lag1', 'ln_daily_rv_lag2',\n",
    "            'ln_weekly_rv_lag1', 'ln_weekly_rv_lag2',\n",
    "            'ln_3_hourly_return_lag1', 'ln_3_hourly_return_lag2',\n",
    "            'ln_daily_return_lag1', 'ln_daily_return_lag2'  \n",
    "        ],\n",
    "        'daily': [\n",
    "            'ln_daily_rv_lag1', 'ln_daily_rv_lag2',\n",
    "            'ln_weekly_rv_lag1', 'ln_weekly_rv_lag2',\n",
    "            'ln_monthly_rv_lag1', 'ln_monthly_rv_lag2',\n",
    "            'ln_daily_return_lag1', 'ln_daily_return_lag2',\n",
    "            'ln_weekly_return_lag1', 'ln_weekly_return_lag2'\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    for freq in frequencies:\n",
    "        models[freq] = {}\n",
    "        for risk_group in ['low', 'medium', 'high']:\n",
    "            group_data = train_data[risk_group].copy()\n",
    "            \n",
    "            target = {\n",
    "                'hourly': 'ln_hourly_rv',\n",
    "                '3hourly': 'ln_3_hourly_rv',\n",
    "                'daily': 'ln_daily_rv'\n",
    "            }[freq]\n",
    "            \n",
    "            features = feature_map[freq]\n",
    "            available_features = [f for f in features if f in group_data.columns]\n",
    "            \n",
    "            if not available_features:\n",
    "                raise ValueError(f\"No valid features for {freq}-{risk_group}\")\n",
    "            \n",
    "            X_train = group_data[available_features].dropna()\n",
    "            y_train = group_data.loc[X_train.index, target]\n",
    "            base_estimator = DecisionTreeRegressor(max_depth=5, random_state=42)\n",
    "\n",
    "            model = BaggingRegressor(\n",
    "                estimator=base_estimator,\n",
    "                n_estimators=100,\n",
    "                max_samples=0.5,  # Fraction of samples to draw for each base estimator\n",
    "                bootstrap=True,   # Enable bootstrapping\n",
    "                random_state=42\n",
    "            )\n",
    "            model.fit(X_train, y_train)\n",
    "            models[freq][risk_group] = model\n",
    "            \n",
    "            # Evaluate on training data\n",
    "            y_pred = model.predict(X_train)\n",
    "            mse_train = mean_squared_error(y_train, y_pred)\n",
    "            r2_train = r2_score(y_train, y_pred)\n",
    "            \n",
    "            # Append to summary\n",
    "            model_summary = pd.concat([\n",
    "                model_summary,\n",
    "                pd.DataFrame({\n",
    "                    'Frequency': [freq],\n",
    "                    'Risk Group': [risk_group.capitalize()],\n",
    "                    'MSE (Train)': [mse_train],\n",
    "                    'R² (Train)': [r2_train]\n",
    "                })\n",
    "            ], ignore_index=True)\n",
    "    \n",
    "    return models, model_summary\n",
    "\n",
    "models, model_summary = train_models_by_frequency_and_risk(train_data_split, ['hourly', '3hourly', 'daily'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Frequency",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Risk Group",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "MSE (Train)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Top Features (Importance)",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "R² (Train)",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "1b1cdec8-8017-4672-9dca-11d8199ed074",
       "rows": [
        [
         "0",
         "hourly",
         "Low",
         "5.292878273991826",
         null,
         "0.18482208547958945"
        ],
        [
         "1",
         "hourly",
         "Medium",
         "5.765934332449836",
         null,
         "0.14211210419504583"
        ],
        [
         "2",
         "hourly",
         "High",
         "5.656643108088014",
         null,
         "0.20457988321768694"
        ],
        [
         "3",
         "3hourly",
         "Low",
         "1.6994874098098687",
         null,
         "0.3750696842980279"
        ],
        [
         "4",
         "3hourly",
         "Medium",
         "1.7682762585177183",
         null,
         "0.31642359678033016"
        ],
        [
         "5",
         "3hourly",
         "High",
         "1.6052731041524535",
         null,
         "0.4442450728621046"
        ],
        [
         "6",
         "daily",
         "Low",
         "0.5572999356711584",
         null,
         "0.6048083215972992"
        ],
        [
         "7",
         "daily",
         "Medium",
         "0.6499572871734496",
         null,
         "0.510110251609587"
        ],
        [
         "8",
         "daily",
         "High",
         "0.49768604939311945",
         null,
         "0.6929438350796632"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 9
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Risk Group</th>\n",
       "      <th>MSE (Train)</th>\n",
       "      <th>Top Features (Importance)</th>\n",
       "      <th>R² (Train)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hourly</td>\n",
       "      <td>Low</td>\n",
       "      <td>5.292878</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.184822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hourly</td>\n",
       "      <td>Medium</td>\n",
       "      <td>5.765934</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.142112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hourly</td>\n",
       "      <td>High</td>\n",
       "      <td>5.656643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.204580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3hourly</td>\n",
       "      <td>Low</td>\n",
       "      <td>1.699487</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.375070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3hourly</td>\n",
       "      <td>Medium</td>\n",
       "      <td>1.768276</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.316424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3hourly</td>\n",
       "      <td>High</td>\n",
       "      <td>1.605273</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.444245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>daily</td>\n",
       "      <td>Low</td>\n",
       "      <td>0.557300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.604808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>daily</td>\n",
       "      <td>Medium</td>\n",
       "      <td>0.649957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.510110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>daily</td>\n",
       "      <td>High</td>\n",
       "      <td>0.497686</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.692944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Frequency Risk Group  MSE (Train) Top Features (Importance)  R² (Train)\n",
       "0    hourly        Low     5.292878                       NaN    0.184822\n",
       "1    hourly     Medium     5.765934                       NaN    0.142112\n",
       "2    hourly       High     5.656643                       NaN    0.204580\n",
       "3   3hourly        Low     1.699487                       NaN    0.375070\n",
       "4   3hourly     Medium     1.768276                       NaN    0.316424\n",
       "5   3hourly       High     1.605273                       NaN    0.444245\n",
       "6     daily        Low     0.557300                       NaN    0.604808\n",
       "7     daily     Medium     0.649957                       NaN    0.510110\n",
       "8     daily       High     0.497686                       NaN    0.692944"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement rolling window\n",
    "Now implement rolling window for the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_window_predictions(X_test, y_test, model, window_size=24, step_ahead=1):\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    dates = []\n",
    "    \n",
    "    max_index = len(X_test) - step_ahead  # Ensure enough data for step_ahead\n",
    "    \n",
    "    for i in range(window_size, max_index + 1):\n",
    "        X_window = X_test.drop(columns=['Date']).iloc[i - window_size:i]\n",
    "        y_pred = model.predict(X_window.tail(1))[0]\n",
    "        \n",
    "        # Capture the target value `step_ahead` steps ahead\n",
    "        actual_index = i + step_ahead - 1\n",
    "        actual_value = y_test.iloc[actual_index]\n",
    "        current_date = X_test['Date'].iloc[actual_index]\n",
    "        \n",
    "        predictions.append(y_pred)\n",
    "        actuals.append(actual_value)\n",
    "        dates.append(current_date)\n",
    "    \n",
    "    return predictions, actuals, dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\young\\AppData\\Local\\Temp\\ipykernel_4348\\2478269679.py:86: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  evaluation_summary = pd.concat([\n",
      "C:\\Users\\young\\AppData\\Local\\Temp\\ipykernel_4348\\2478269679.py:106: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  detailed_results = pd.concat([detailed_results, ticker_df], ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Frequency",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Risk Group",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Ticker",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "MSE (Test)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "R²",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "735f7db3-ab4d-46cc-8748-2d4be48bc663",
       "rows": [
        [
         "0",
         "hourly",
         "low",
         "BTC-USD",
         "6.053752388868096",
         "0.054019069748741266"
        ],
        [
         "1",
         "hourly",
         "medium",
         "ETH-USD",
         "5.813917270317173",
         "0.04799335894602896"
        ],
        [
         "2",
         "hourly",
         "medium",
         "XRP-USD",
         "5.939899280811516",
         "0.1669126088769477"
        ],
        [
         "3",
         "hourly",
         "high",
         "DOGE-USD",
         "5.919613250243796",
         "0.06397897375986294"
        ],
        [
         "4",
         "hourly",
         "high",
         "SOL-USD",
         "5.892804830793595",
         "0.03204243080202307"
        ],
        [
         "5",
         "3hourly",
         "low",
         "BTC-USD",
         "2.156697848810512",
         "0.09894368136777698"
        ],
        [
         "6",
         "3hourly",
         "medium",
         "ETH-USD",
         "1.8866638024703315",
         "0.1298750598607139"
        ],
        [
         "7",
         "3hourly",
         "medium",
         "XRP-USD",
         "2.019422867884992",
         "0.34497916290292185"
        ],
        [
         "8",
         "3hourly",
         "high",
         "DOGE-USD",
         "1.8102452250332741",
         "0.1758653135397512"
        ],
        [
         "9",
         "3hourly",
         "high",
         "SOL-USD",
         "1.6592815739362934",
         "0.07871665312493625"
        ],
        [
         "10",
         "daily",
         "low",
         "BTC-USD",
         "1.2460096141350956",
         "-0.1745047554312169"
        ],
        [
         "11",
         "daily",
         "medium",
         "ETH-USD",
         "0.9783900067080761",
         "-0.03392500167841672"
        ],
        [
         "12",
         "daily",
         "medium",
         "XRP-USD",
         "1.5356587098517223",
         "0.2245175109300135"
        ],
        [
         "13",
         "daily",
         "high",
         "DOGE-USD",
         "0.9005414803386808",
         "0.0779566793213261"
        ],
        [
         "14",
         "daily",
         "high",
         "SOL-USD",
         "0.7857463763239128",
         "-0.044125718819296944"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 15
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Risk Group</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>MSE (Test)</th>\n",
       "      <th>R²</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hourly</td>\n",
       "      <td>low</td>\n",
       "      <td>BTC-USD</td>\n",
       "      <td>6.053752</td>\n",
       "      <td>0.054019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hourly</td>\n",
       "      <td>medium</td>\n",
       "      <td>ETH-USD</td>\n",
       "      <td>5.813917</td>\n",
       "      <td>0.047993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hourly</td>\n",
       "      <td>medium</td>\n",
       "      <td>XRP-USD</td>\n",
       "      <td>5.939899</td>\n",
       "      <td>0.166913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hourly</td>\n",
       "      <td>high</td>\n",
       "      <td>DOGE-USD</td>\n",
       "      <td>5.919613</td>\n",
       "      <td>0.063979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hourly</td>\n",
       "      <td>high</td>\n",
       "      <td>SOL-USD</td>\n",
       "      <td>5.892805</td>\n",
       "      <td>0.032042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3hourly</td>\n",
       "      <td>low</td>\n",
       "      <td>BTC-USD</td>\n",
       "      <td>2.156698</td>\n",
       "      <td>0.098944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3hourly</td>\n",
       "      <td>medium</td>\n",
       "      <td>ETH-USD</td>\n",
       "      <td>1.886664</td>\n",
       "      <td>0.129875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3hourly</td>\n",
       "      <td>medium</td>\n",
       "      <td>XRP-USD</td>\n",
       "      <td>2.019423</td>\n",
       "      <td>0.344979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3hourly</td>\n",
       "      <td>high</td>\n",
       "      <td>DOGE-USD</td>\n",
       "      <td>1.810245</td>\n",
       "      <td>0.175865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3hourly</td>\n",
       "      <td>high</td>\n",
       "      <td>SOL-USD</td>\n",
       "      <td>1.659282</td>\n",
       "      <td>0.078717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>daily</td>\n",
       "      <td>low</td>\n",
       "      <td>BTC-USD</td>\n",
       "      <td>1.246010</td>\n",
       "      <td>-0.174505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>daily</td>\n",
       "      <td>medium</td>\n",
       "      <td>ETH-USD</td>\n",
       "      <td>0.978390</td>\n",
       "      <td>-0.033925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>daily</td>\n",
       "      <td>medium</td>\n",
       "      <td>XRP-USD</td>\n",
       "      <td>1.535659</td>\n",
       "      <td>0.224518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>daily</td>\n",
       "      <td>high</td>\n",
       "      <td>DOGE-USD</td>\n",
       "      <td>0.900541</td>\n",
       "      <td>0.077957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>daily</td>\n",
       "      <td>high</td>\n",
       "      <td>SOL-USD</td>\n",
       "      <td>0.785746</td>\n",
       "      <td>-0.044126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Frequency Risk Group    Ticker  MSE (Test)        R²\n",
       "0     hourly        low   BTC-USD    6.053752  0.054019\n",
       "1     hourly     medium   ETH-USD    5.813917  0.047993\n",
       "2     hourly     medium   XRP-USD    5.939899  0.166913\n",
       "3     hourly       high  DOGE-USD    5.919613  0.063979\n",
       "4     hourly       high   SOL-USD    5.892805  0.032042\n",
       "5    3hourly        low   BTC-USD    2.156698  0.098944\n",
       "6    3hourly     medium   ETH-USD    1.886664  0.129875\n",
       "7    3hourly     medium   XRP-USD    2.019423  0.344979\n",
       "8    3hourly       high  DOGE-USD    1.810245  0.175865\n",
       "9    3hourly       high   SOL-USD    1.659282  0.078717\n",
       "10     daily        low   BTC-USD    1.246010 -0.174505\n",
       "11     daily     medium   ETH-USD    0.978390 -0.033925\n",
       "12     daily     medium   XRP-USD    1.535659  0.224518\n",
       "13     daily       high  DOGE-USD    0.900541  0.077957\n",
       "14     daily       high   SOL-USD    0.785746 -0.044126"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate_models_on_test_data(test_data_split, models, frequencies, window_size=24):\n",
    "    evaluation_summary = pd.DataFrame(columns=['Frequency', 'Risk Group', 'Ticker', 'MSE (Test)', 'R²'])\n",
    "    detailed_results = pd.DataFrame(columns=['Date', 'Ticker', 'Risk Group', 'Frequency', 'Predicted', 'Actual'])\n",
    "    \n",
    "    # Feature map from your previous code\n",
    "    feature_map = {\n",
    "        'hourly': [\n",
    "            'ln_hourly_rv_lag1', 'ln_hourly_rv_lag2',\n",
    "            'ln_3_hourly_rv_lag1', 'ln_3_hourly_rv_lag2',\n",
    "            'ln_daily_rv_lag1', 'ln_daily_rv_lag2',\n",
    "            'ln_hourly_return_lag1', 'ln_hourly_return_lag2',\n",
    "            'ln_3_hourly_return_lag1', 'ln_3_hourly_return_lag2'\n",
    "        ],\n",
    "        '3hourly': [\n",
    "            'ln_3_hourly_rv_lag1', 'ln_3_hourly_rv_lag2',\n",
    "            'ln_daily_rv_lag1', 'ln_daily_rv_lag2',\n",
    "            'ln_weekly_rv_lag1', 'ln_weekly_rv_lag2',\n",
    "            'ln_3_hourly_return_lag1', 'ln_3_hourly_return_lag2',\n",
    "            'ln_daily_return_lag1', 'ln_daily_return_lag2'\n",
    "        ],\n",
    "        'daily': [\n",
    "            'ln_daily_rv_lag1', 'ln_daily_rv_lag2',\n",
    "            'ln_weekly_rv_lag1', 'ln_weekly_rv_lag2',\n",
    "            'ln_monthly_rv_lag1', 'ln_monthly_rv_lag2',\n",
    "            'ln_daily_return_lag1', 'ln_daily_return_lag2',\n",
    "            'ln_weekly_return_lag1', 'ln_weekly_return_lag2'\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    for freq in frequencies:\n",
    "        for risk_group in ['low', 'medium', 'high']:\n",
    "            model = models[freq][risk_group]\n",
    "            group_data = test_data_split[risk_group].copy()\n",
    "            \n",
    "            # Define target and step_ahead based on frequency\n",
    "            target = {\n",
    "                'hourly': 'ln_hourly_rv',\n",
    "                '3hourly': 'ln_3_hourly_rv',\n",
    "                'daily': 'ln_daily_rv'\n",
    "            }[freq]\n",
    "            \n",
    "            step_ahead = {\n",
    "                'hourly': 1,\n",
    "                '3hourly': 3,\n",
    "                'daily': 24\n",
    "            }[freq]\n",
    "            \n",
    "            features = feature_map[freq]\n",
    "            available_features = [f for f in features if f in group_data.columns]\n",
    "            \n",
    "            if not available_features:\n",
    "                raise ValueError(f\"No valid features for {freq}-{risk_group}\")\n",
    "            \n",
    "            unique_tickers = group_data['Ticker'].unique()\n",
    "            \n",
    "            for ticker in unique_tickers:\n",
    "                ticker_data = group_data[group_data['Ticker'] == ticker].copy()\n",
    "                \n",
    "                # Validate features and target\n",
    "                if not all(f in ticker_data.columns for f in available_features) or target not in ticker_data.columns:\n",
    "                    print(f\"Skipping {ticker}: missing features or target for {freq}-{risk_group}\")\n",
    "                    continue\n",
    "                \n",
    "                # Prepare data with Date column\n",
    "                X_test = ticker_data[['Date'] + available_features].dropna()\n",
    "                y_test = ticker_data.loc[X_test.index, target]\n",
    "                \n",
    "                # Ensure sufficient data for window and step_ahead\n",
    "                if len(X_test) < window_size + step_ahead:\n",
    "                    print(f\"Skipping {ticker}: insufficient data ({len(X_test)} rows)\")\n",
    "                    continue\n",
    "                \n",
    "                # Get predictions using rolling window\n",
    "                predictions, actuals, dates = rolling_window_predictions(\n",
    "                    X_test, y_test, model, window_size=window_size, step_ahead=step_ahead\n",
    "                )\n",
    "                \n",
    "                if len(predictions) == 0:\n",
    "                    continue\n",
    "                \n",
    "                # Calculate metrics\n",
    "                mse = mean_squared_error(actuals, predictions)\n",
    "                r2 = r2_score(actuals, predictions)\n",
    "                \n",
    "                # Append to summary\n",
    "                evaluation_summary = pd.concat([\n",
    "                    evaluation_summary,\n",
    "                    pd.DataFrame({\n",
    "                        'Frequency': [freq],\n",
    "                        'Risk Group': [risk_group],\n",
    "                        'Ticker': [ticker],\n",
    "                        'MSE (Test)': [mse],\n",
    "                        'R²': [r2]\n",
    "                    })\n",
    "                ], ignore_index=True)\n",
    "                \n",
    "                # Append detailed results\n",
    "                ticker_df = pd.DataFrame({\n",
    "                    'Date': dates,\n",
    "                    'Ticker': ticker,\n",
    "                    'Risk Group': risk_group,\n",
    "                    'Frequency': freq,\n",
    "                    'Predicted': predictions,\n",
    "                    'Actual': actuals\n",
    "                })\n",
    "                detailed_results = pd.concat([detailed_results, ticker_df], ignore_index=True)\n",
    "    \n",
    "    return evaluation_summary, detailed_results\n",
    "\n",
    "evaluation_summary, detailed_results = evaluate_models_on_test_data(test_data_split, models, ['hourly', '3hourly', 'daily'])\n",
    "\n",
    "evaluation_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the detailed results\n",
    "detailed_results.to_csv('../../results/bagging_dt.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

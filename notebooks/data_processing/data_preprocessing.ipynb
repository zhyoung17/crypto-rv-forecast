{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Raw file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path\n",
    "data_route = \"../../data/raw_data.csv\"\n",
    "data = pd.read_csv(data_route)\n",
    "data['Date'] = pd.to_datetime(data['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Date",
         "rawType": "datetime64[ns, UTC]",
         "type": "unknown"
        },
        {
         "name": "Open",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "High",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Low",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Volume",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Ticker",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "effa943e-593b-4e56-a647-e52b731b269c",
       "rows": [
        [
         "0",
         "2023-04-03 13:30:00+00:00",
         "408.8500061035156",
         "411.30999755859375",
         "408.8200073242188",
         "411.1900024414063",
         "14278892.0",
         "SPY"
        ],
        [
         "1",
         "2023-04-03 14:30:00+00:00",
         "411.2000122070313",
         "411.3699951171875",
         "408.4400024414063",
         "409.0400085449219",
         "10506955.0",
         "SPY"
        ],
        [
         "2",
         "2023-04-03 15:30:00+00:00",
         "409.05999755859375",
         "409.8900146484375",
         "408.9700012207031",
         "409.6401062011719",
         "7643987.0",
         "SPY"
        ],
        [
         "3",
         "2023-04-03 16:30:00+00:00",
         "409.6449890136719",
         "409.7799987792969",
         "408.9500122070313",
         "409.2099914550781",
         "5003256.0",
         "SPY"
        ],
        [
         "4",
         "2023-04-03 17:30:00+00:00",
         "409.2200012207031",
         "409.6799926757813",
         "408.8999938964844",
         "409.6099853515625",
         "6087517.0",
         "SPY"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-03 13:30:00+00:00</td>\n",
       "      <td>408.850006</td>\n",
       "      <td>411.309998</td>\n",
       "      <td>408.820007</td>\n",
       "      <td>411.190002</td>\n",
       "      <td>14278892.0</td>\n",
       "      <td>SPY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-04-03 14:30:00+00:00</td>\n",
       "      <td>411.200012</td>\n",
       "      <td>411.369995</td>\n",
       "      <td>408.440002</td>\n",
       "      <td>409.040009</td>\n",
       "      <td>10506955.0</td>\n",
       "      <td>SPY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-04-03 15:30:00+00:00</td>\n",
       "      <td>409.059998</td>\n",
       "      <td>409.890015</td>\n",
       "      <td>408.970001</td>\n",
       "      <td>409.640106</td>\n",
       "      <td>7643987.0</td>\n",
       "      <td>SPY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-04-03 16:30:00+00:00</td>\n",
       "      <td>409.644989</td>\n",
       "      <td>409.779999</td>\n",
       "      <td>408.950012</td>\n",
       "      <td>409.209991</td>\n",
       "      <td>5003256.0</td>\n",
       "      <td>SPY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-04-03 17:30:00+00:00</td>\n",
       "      <td>409.220001</td>\n",
       "      <td>409.679993</td>\n",
       "      <td>408.899994</td>\n",
       "      <td>409.609985</td>\n",
       "      <td>6087517.0</td>\n",
       "      <td>SPY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Date        Open        High         Low       Close  \\\n",
       "0 2023-04-03 13:30:00+00:00  408.850006  411.309998  408.820007  411.190002   \n",
       "1 2023-04-03 14:30:00+00:00  411.200012  411.369995  408.440002  409.040009   \n",
       "2 2023-04-03 15:30:00+00:00  409.059998  409.890015  408.970001  409.640106   \n",
       "3 2023-04-03 16:30:00+00:00  409.644989  409.779999  408.950012  409.209991   \n",
       "4 2023-04-03 17:30:00+00:00  409.220001  409.679993  408.899994  409.609985   \n",
       "\n",
       "       Volume Ticker  \n",
       "0  14278892.0    SPY  \n",
       "1  10506955.0    SPY  \n",
       "2   7643987.0    SPY  \n",
       "3   5003256.0    SPY  \n",
       "4   6087517.0    SPY  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of days of data for each ticker:\n",
      "Ticker\n",
      "BTC-USD     697\n",
      "DOGE-USD    697\n",
      "ETH-USD     697\n",
      "SOL-USD     697\n",
      "SPY         477\n",
      "XRP-USD     697\n",
      "Name: Date, dtype: int64\n",
      "\n",
      "Daily data with number of transactions:\n",
      "    Ticker                      Date          Open          High  \\\n",
      "0  BTC-USD 2023-04-01 00:00:00+00:00  28473.332031  28802.457031   \n",
      "1  BTC-USD 2023-04-02 00:00:00+00:00  28462.845703  28518.958984   \n",
      "2  BTC-USD 2023-04-03 00:00:00+00:00  28183.080078  28475.623047   \n",
      "3  BTC-USD 2023-04-04 00:00:00+00:00  27795.273438  28433.742188   \n",
      "4  BTC-USD 2023-04-05 00:00:00+00:00  28169.726562  28739.238281   \n",
      "5  BTC-USD 2023-04-06 00:00:00+00:00  28175.226562  28178.384766   \n",
      "6  BTC-USD 2023-04-07 00:00:00+00:00  28038.966797  28111.593750   \n",
      "7  BTC-USD 2023-04-08 00:00:00+00:00  27923.943359  28159.863281   \n",
      "8  BTC-USD 2023-04-09 00:00:00+00:00  27952.367188  28532.830078   \n",
      "9  BTC-USD 2023-04-10 00:00:00+00:00  28336.027344  29771.464844   \n",
      "\n",
      "            Low         Close        Volume  Daily_Transactions  \n",
      "0  28297.171875  28466.199219  3.055288e+08                  24  \n",
      "1  27884.087891  28202.138672  2.249324e+09                  24  \n",
      "2  27276.720703  27786.367188  7.748741e+09                  24  \n",
      "3  27681.304688  28170.050781  1.185264e+09                  24  \n",
      "4  27843.763672  28175.435547  3.515677e+09                  24  \n",
      "5  27765.341797  28034.193359  9.813422e+08                  24  \n",
      "6  27794.031250  27925.455078  2.678426e+08                  24  \n",
      "7  27883.386719  27945.478516  4.694487e+08                  24  \n",
      "8  27828.480469  28348.171875  3.246046e+09                  24  \n",
      "9  28189.271484  29650.720703  7.995150e+09                  24  \n",
      "\n",
      "Average daily number of transactions for each ticker:\n",
      "Ticker\n",
      "BTC-USD     23.912482\n",
      "DOGE-USD    23.902439\n",
      "ETH-USD     23.911047\n",
      "SOL-USD     23.911047\n",
      "SPY          6.958071\n",
      "XRP-USD     23.912482\n",
      "Name: Daily_Transactions, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "daily_data = (\n",
    "    data.groupby(['Ticker', pd.Grouper(key='Date', freq='D')])  # Group by Ticker and Date (daily frequency)\n",
    "    .agg({\n",
    "        'Open': 'first',   # First price of the day\n",
    "        'High': 'max',     # Highest price of the day\n",
    "        'Low': 'min',      # Lowest price of the day\n",
    "        'Close': 'last',   # Last price of the day\n",
    "        'Volume': 'sum',   # Total volume of the day\n",
    "        'Ticker': 'size'   # Count the number of hourly data points (transactions)\n",
    "    })\n",
    "    .rename(columns={'Ticker': 'Daily_Transactions'})  # Rename the count column\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Calculate the total number of days of data for each ticker\n",
    "days_per_ticker = daily_data.groupby('Ticker')['Date'].nunique()\n",
    "\n",
    "# Display the results\n",
    "print(\"Number of days of data for each ticker:\")\n",
    "print(days_per_ticker)\n",
    "\n",
    "print(\"\\nDaily data with number of transactions:\")\n",
    "print(daily_data.head(10))\n",
    "\n",
    "# Average daily number of transactions\n",
    "avg_daily_transactions = daily_data.groupby('Ticker')['Daily_Transactions'].mean()\n",
    "print(\"\\nAverage daily number of transactions for each ticker:\")\n",
    "print(avg_daily_transactions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This finding makes sense, as SPY does not operate over the weekends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features engineering\n",
    "Now we have the calculate the key metrics, similar to how we did it in the group component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the hourly, 3-hourly, daily, weekly, and monthly \n",
    "Defined by Corsi 2009, weekly RV is the rolling average of 7 days RV, and monthly RV is the rolling average of 30 days RV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\young\\AppData\\Local\\Temp\\ipykernel_23508\\4250605515.py:34: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  data.groupby(['Ticker', pd.Grouper(key='Date', freq='3H')])['ln_hourly_return']\n",
      "c:\\Users\\young\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure Date is datetime\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "\n",
    "# Sort data by Ticker and Date\n",
    "data = data.sort_values(['Ticker', 'Date'])\n",
    "\n",
    "# Calculate hourly log returns\n",
    "data['ln_hourly_return'] = data.groupby('Ticker', group_keys=False)['Close'].apply(lambda x: np.log(x).diff())\n",
    "\n",
    "# Calculate 3-hourly log returns\n",
    "data['ln_3_hourly_return'] = data.groupby('Ticker', group_keys=False)['Close'].apply(lambda x: np.log(x).diff(3))\n",
    "\n",
    "# Extract daily closing prices\n",
    "daily_close = (\n",
    "    data.groupby(['Ticker', pd.Grouper(key='Date', freq='D')])['Close']\n",
    "    .last()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Calculate daily log returns\n",
    "daily_close['ln_daily_return'] = daily_close.groupby('Ticker', group_keys=False)['Close'].apply(lambda x: np.log(x).diff())\n",
    "\n",
    "# Merge daily log returns back into the original DataFrame\n",
    "data = data.merge(daily_close[['Ticker', 'Date', 'ln_daily_return']], on=['Ticker', 'Date'], how='left')\n",
    "\n",
    "# Calculate realized variance\n",
    "data['hourly_rv'] = data['ln_hourly_return']**2\n",
    "\n",
    "# 3-hourly RV: Sum of squared log returns over 3 hours\n",
    "data['3_hourly_rv'] = (\n",
    "    data.groupby(['Ticker', pd.Grouper(key='Date', freq='3H')])['ln_hourly_return']\n",
    "    .transform(lambda x: (x**2).sum())\n",
    ")\n",
    "\n",
    "# Daily RV: Sum of squared hourly log returns over 24 hours\n",
    "data['daily_rv'] = (\n",
    "    data.groupby(['Ticker', pd.Grouper(key='Date', freq='D')])['ln_hourly_return']\n",
    "    .transform(lambda x: (x**2).sum())\n",
    ")\n",
    "\n",
    "# Logarithmic transformation of realized variance\n",
    "data['ln_hourly_rv'] = np.log(data['hourly_rv'])\n",
    "data['ln_3_hourly_rv'] = np.log(data['3_hourly_rv'])\n",
    "data['ln_daily_rv'] = np.log(data['daily_rv'])\n",
    "\n",
    "# Handle -inf for ln_hourly_rv, make it 0\n",
    "data['ln_hourly_rv'] = data['ln_hourly_rv'].replace(-np.inf, 0)\n",
    "\n",
    "# Do a forward fill of missing daily RV values\n",
    "data['ln_daily_rv'] = data.groupby('Ticker')['ln_daily_rv'].ffill() \n",
    "\n",
    "# Create a weekly rv\n",
    "data['weekly_rv'] = data.groupby('Ticker')['daily_rv'].transform(lambda x: x.rolling(window=7*24).mean())\n",
    "data['ln_weekly_rv'] = np.log(data['weekly_rv'])\n",
    "\n",
    "# Create a monthly rv\n",
    "data['monthly_rv'] = data.groupby('Ticker')['daily_rv'].transform(lambda x: x.rolling(window=30).mean())\n",
    "data['ln_monthly_rv'] = np.log(data['monthly_rv'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lag the RV by 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lag all realized variance measures by 1\n",
    "data['ln_hourly_rv_lag1'] = data.groupby('Ticker')['ln_hourly_rv'].shift(1)\n",
    "data['ln_3_hourly_rv_lag1'] = data.groupby('Ticker')['ln_3_hourly_rv'].shift(1)\n",
    "data['ln_daily_rv_lag1'] = data.groupby('Ticker')['ln_daily_rv'].shift(1)\n",
    "data['ln_weekly_rv_lag1'] = data.groupby('Ticker')['ln_weekly_rv'].shift(1)\n",
    "data['ln_monthly_rv_lag1'] = data.groupby('Ticker')['ln_monthly_rv'].shift(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop all non-lg data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the intermediate columns\n",
    "data = data.drop(columns=['hourly_rv', '3_hourly_rv', 'daily_rv', 'weekly_rv', 'monthly_rv'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "In my model, I wish to classify each coin as either high risk, medium risk, or low risk, based on their hourly realised variance. High RV constitutes as high risk, and likewise for medium risk and low risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Ticker  ln_hourly_rv  ln_3_hourly_rv  ln_daily_rv  Composite_Score  \\\n",
      "0   BTC-USD    -12.737050      -10.683420    -7.966684        -9.735778   \n",
      "2   ETH-USD    -12.376387      -10.285618    -7.575197        -9.348561   \n",
      "5   XRP-USD    -11.950287       -9.879607    -7.202063        -8.954971   \n",
      "1  DOGE-USD    -11.601146       -9.521515    -6.835879        -8.594623   \n",
      "3   SOL-USD    -11.184339       -9.125065    -6.520952        -8.234863   \n",
      "4       SPY    -13.621181      -11.958249   -10.287492       -11.455457   \n",
      "\n",
      "          Risk  \n",
      "0     Low Risk  \n",
      "2  Medium Risk  \n",
      "5  Medium Risk  \n",
      "1    High Risk  \n",
      "3    High Risk  \n",
      "4     Baseline  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Aggregate hourly, 3-hourly, and daily realized variance for each ticker\n",
    "ticker_rv_aggregated = (\n",
    "    data.groupby('Ticker')\n",
    "    .agg({\n",
    "        'ln_hourly_rv': 'mean',\n",
    "        'ln_3_hourly_rv': 'mean',\n",
    "        'ln_daily_rv': 'mean'\n",
    "    })\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Define weights for each metric --> Give more weights to daily RV, since it's more stable\n",
    "weights = {\n",
    "    'ln_hourly_rv': 0.2,  # 20% weight\n",
    "    'ln_3_hourly_rv': 0.3,  # 30% weight\n",
    "    'ln_daily_rv': 0.5  # 50% weight\n",
    "}\n",
    "\n",
    "# Calculate the composite score\n",
    "ticker_rv_aggregated['Composite_Score'] = (\n",
    "    ticker_rv_aggregated['ln_hourly_rv'] * weights['ln_hourly_rv'] +\n",
    "    ticker_rv_aggregated['ln_3_hourly_rv'] * weights['ln_3_hourly_rv'] +\n",
    "    ticker_rv_aggregated['ln_daily_rv'] * weights['ln_daily_rv']\n",
    ")\n",
    "\n",
    "# Define dynamic bins based on the composite score\n",
    "min_score = ticker_rv_aggregated['Composite_Score'].min()\n",
    "max_score = ticker_rv_aggregated['Composite_Score'].max()\n",
    "\n",
    "# Create 3 bins (Low, Medium, High) using percentiles or custom logic\n",
    "bins = [\n",
    "    min_score, \n",
    "    ticker_rv_aggregated['Composite_Score'].quantile(0.33),  # 33rd percentile\n",
    "    ticker_rv_aggregated['Composite_Score'].quantile(0.66),  # 66th percentile\n",
    "    max_score\n",
    "]\n",
    "\n",
    "bins = sorted(list(set(bins)))  # Remove duplicates and sort\n",
    "\n",
    "# Classify tickers\n",
    "risk_labels = ['Low Risk', 'Medium Risk', 'High Risk']  # Initial categories\n",
    "ticker_rv_aggregated['Risk'] = pd.cut(\n",
    "    ticker_rv_aggregated['Composite_Score'],\n",
    "    bins=bins,\n",
    "    labels=risk_labels,  # Use the initial categories\n",
    "    include_lowest=True  # Include the minimum value in the first bin\n",
    ")\n",
    "\n",
    "# Add \"Baseline\" to the categories of the 'Risk' column\n",
    "ticker_rv_aggregated['Risk'] = ticker_rv_aggregated['Risk'].cat.add_categories('Baseline')\n",
    "\n",
    "# For the ticker \"SPY\": Set the risk as \"Baseline\"\n",
    "ticker_rv_aggregated.loc[ticker_rv_aggregated['Ticker'] == 'SPY', 'Risk'] = 'Baseline'\n",
    "\n",
    "# Sort by Risk\n",
    "ticker_rv_aggregated = ticker_rv_aggregated.sort_values('Risk')\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(ticker_rv_aggregated)\n",
    "\n",
    "# Merge back to original data\n",
    "data = data.merge(ticker_rv_aggregated[['Ticker', 'Risk']], on='Ticker', how='left')\n",
    "\n",
    "# Just to be sure, make sure date is in datetime format\n",
    "data['Date'] = pd.to_datetime(data['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data\n",
    "data.to_csv(\"../../data/processed_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
